{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b22931-96b4-4c19-a74f-44e0185ab2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_cloud_services in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (0.6.30)\n",
      "Requirement already satisfied: openpyxl in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (8.1.8)\n",
      "Requirement already satisfied: llama-cloud==0.1.23 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (0.1.23)\n",
      "Requirement already satisfied: llama-index-core>=0.12.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (0.12.41)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (4.3.7)\n",
      "Requirement already satisfied: pydantic!=2.10,>=2.8 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (2.11.4)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-cloud==0.1.23->llama_cloud_services) (2025.4.26)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-cloud==0.1.23->llama_cloud_services) (0.28.1)\n",
      "Requirement already satisfied: et-xmlfile in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: anyio in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx>=0.20.0->llama-cloud==0.1.23->llama_cloud_services) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx>=0.20.0->llama-cloud==0.1.23->llama_cloud_services) (1.0.8)\n",
      "Requirement already satisfied: idna in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx>=0.20.0->llama-cloud==0.1.23->llama_cloud_services) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud==0.1.23->llama_cloud_services) (0.14.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (3.11.18)\n",
      "Requirement already satisfied: aiosqlite in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (2025.3.2)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama_cloud_services) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (1.20.0)\n",
      "Requirement already satisfied: griffe in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core>=0.12.0->llama_cloud_services) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core>=0.12.0->llama_cloud_services) (3.1.6)\n",
      "Requirement already satisfied: joblib in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama_cloud_services) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama_cloud_services) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=2.10,>=2.8->llama_cloud_services) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=2.10,>=2.8->llama_cloud_services) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=2.10,>=2.8->llama_cloud_services) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama_cloud_services) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama_cloud_services) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama_cloud_services) (3.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.12.0->llama_cloud_services) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.23->llama_cloud_services) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from dataclasses-json->llama-index-core>=0.12.0->llama_cloud_services) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.12.0->llama_cloud_services) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core>=0.12.0->llama_cloud_services) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core>=0.12.0->llama_cloud_services) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_cloud_services openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9627dd-5608-4da8-9f1a-8ea9589a003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from llama_cloud_services import LlamaExtract\n",
    "from financial_schemas_endowment_final import generate_endowment_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf875a82-1028-4b54-8807-1d1dde9cca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "FISCAL_YEAR = 2024 #Change the year if you want different years\n",
    "EndowmentSchema = generate_endowment_schema(FISCAL_YEAR)\n",
    "\n",
    "PDF_ROOT = \"private_universities/university_pdfs\" # Change this to the point to the directory where you are storing the pdfs after scraping\n",
    "OUTPUT_ROOT = \"output_endowment_final\" # Make this point to the directory/folder where you want to store the excel files with information extracted\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)  \n",
    "AGENT_ID = \"56843d2c-7e9b-445d-b634-9833dd1cb4db\" #Different based on your LLamaCloud account\n",
    "api_key = os.getenv(\"LLAMACLOUD_API_KEY\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47855a29-4fc8-4dae-b036-4626be1954da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/8j3nd3m95y1brb0j52fx43fr0000gn/T/ipykernel_11736/1010406420.py:11: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  agent.data_schema = EndowmentSchema.schema()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.70s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.87s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.57s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.75s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:12<00:00, 12.08s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.14s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.10s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.03s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.66s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.59s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:15<00:00, 15.55s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.13s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.92s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.37s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:19<00:00, 19.46s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:21<00:00, 21.97s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.88s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.97s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.11s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.09s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:14<00:00, 14.02s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.18s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.02s/it]]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.76s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.01s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.98s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.34s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.23s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.53s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.55s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.86s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.98s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.40s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.91s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.14s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.02s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.37s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.68s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.42s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.88s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.81s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.78s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.07s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.91s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.69s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.34s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:16<00:00, 16.17s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:18<00:00, 18.84s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:03<00:00,  3.27s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.92s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.32s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.19s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.63s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:13<00:00, 13.92s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.47s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.17s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.44s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.99s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.66s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.61s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.56s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:24<00:00, 24.02s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.75s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:39<00:00, 39.82s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:05<00:00,  5.57s/it]\n"
     ]
    }
   ],
   "source": [
    "extractor = LlamaExtract(\n",
    "    api_key=\"llx-63CU3PdyDo0d230ureocmy9JOHgnPwYgE2HETi55DqzYCIpy\",  # Add your Llamacloud API Key \n",
    "    project_id=\"8c10e62e-3810-4193-915d-d2d11105826d\"  #Change the project ID only if Luis has asked you. This is dependent on the llamacloud account\n",
    ")\n",
    "\n",
    "#agent = extractor.create_agent(name = \"endowment-parser-2024\", data_schema=EndowmentAndInvestmentLevels_2024_25)\n",
    "\n",
    "agent = extractor.get_agent(id = AGENT_ID)\n",
    "\n",
    "#uncomment the following lines if you updated the schema\n",
    "agent.data_schema = EndowmentSchema.schema()\n",
    "agent.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a8d24-9e3e-40eb-a1c0-9fe4e2025a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"additionalProperties\": false,\n",
      "  \"properties\": {\n",
      "    \"endowment_net_assets_eoy_total\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Total endowment net assets for the 2024 fiscal year (in thousands). Only extract from a table titled 'Changes in Endowment Net Assets' located in the Notes section. Only use data explicitly labeled as '2024', 'FY2024', or 'as of June 30, 2024'. Do not extract from general balance sheets, rollforwards, or systemwide summaries. Standardize all values to $000s using table metadata or heuristics.\"\n",
      "    },\n",
      "    \"endowment_net_assets_eoy_with_donor_restrictions\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Total donor-restricted endowment net assets as of June 30, 2024 (in thousands). Must be extracted from a 'Changes in Endowment Net Assets' table in the Notes section. Exclude all 2023 or earlier data. Must be clearly labeled as 2024.\"\n",
      "    },\n",
      "    \"endowment_net_assets_eoy_with_donor_restrictions_temporarily_restricted\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Temporarily restricted portion of donor-restricted endowment net assets for FY2024 (in thousands). Must appear in a table under Notes with a clear 2024 label. Ignore unlabeled or earlier year data.\"\n",
      "    },\n",
      "    \"endowment_net_assets_eoy_with_donor_restrictions_permanently_restricted\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Permanently restricted portion of donor-restricted endowment net assets for FY2024 (in thousands). Only extract from Notes where clearly labeled as 2024.\"\n",
      "    },\n",
      "    \"endowment_net_assets_eoy_without_donor_restrictions\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Unrestricted portion of endowment net assets for the 2024\\u20132025 fiscal year (in thousands). Must be pulled from a 'Changes in Endowment Net Assets' table in Notes. Only extract if labeled as 2024. Ignore prior-year or aggregated system data.\"\n",
      "    },\n",
      "    \"appropriation_of_endowment_for_expenditure_total\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Total appropriations or spending from the endowment during 2024\\u20132025 (in thousands). Only extract from the 'Changes in Endowment Net Assets' table in the Notes section. Do not infer from general text or extract from unlabeled rows.\"\n",
      "    },\n",
      "    \"appropriation_of_endowment_for_expenditure_with_donor_restrictions\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Appropriations from donor-restricted endowment funds for FY2024 (in thousands). Must appear in a 2024-labeled row of the Notes. Ignore prior years and total-only rows.\"\n",
      "    },\n",
      "    \"appropriation_of_endowment_for_expenditure_without_donor_restrictions\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Appropriations from unrestricted endowment funds during 2024\\u20132025 (in thousands). Must appear in a 'Changes in Endowment Net Assets' table and be labeled 2024. Ignore earlier data.\"\n",
      "    },\n",
      "    \"investment_level_1\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Fair value of Level 1 investments (quoted market prices) at June 30, 2024 (in thousands). Only extract from a fair value hierarchy table in the Notes section. Ensure the table is for the university, not an enterprise or foundation. \"\n",
      "    },\n",
      "    \"investment_level_2\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Fair value of Level 2 investments (observable inputs) as of the end of FY2024 (in thousands). Must be extracted from the same fair value hierarchy table in the Notes section. Only use data labeled 2024. Avoid mixing rows from different years or sources.\"\n",
      "    },\n",
      "    \"investment_level_3\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Fair value of Level 3 investments (unobservable inputs) at year-end 2024 (in thousands). Only extract from 2024-labeled fair value tables in the Notes. Ignore mixed-year summaries.\"\n",
      "    },\n",
      "    \"investments_measured_at_nav\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Total value of investments measured at Net Asset Value (NAV) at June 30, 2024 (in thousands). Must be extracted from a Fair Value Hierarchy table in the Notes. Include Life Insurance Cash Surrender value if presented separately and applicable. Ensure values are labeled as 2024 and not drawn from system-wide or multi-entity tables.\"\n",
      "    },\n",
      "    \"investments_total_fair_value\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"Total fair value of all university investments as of fiscal year end 2024\\u20132025 (in thousands). Must be sourced from the same fair value hierarchy table as NAV and Levels 1\\u20133. Do not infer from text, and ignore totals from earlier years, foundations, or consolidated entities.\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"endowment_net_assets_eoy_total\",\n",
      "    \"endowment_net_assets_eoy_with_donor_restrictions\",\n",
      "    \"endowment_net_assets_eoy_with_donor_restrictions_temporarily_restricted\",\n",
      "    \"endowment_net_assets_eoy_with_donor_restrictions_permanently_restricted\",\n",
      "    \"endowment_net_assets_eoy_without_donor_restrictions\",\n",
      "    \"appropriation_of_endowment_for_expenditure_total\",\n",
      "    \"appropriation_of_endowment_for_expenditure_with_donor_restrictions\",\n",
      "    \"appropriation_of_endowment_for_expenditure_without_donor_restrictions\",\n",
      "    \"investment_level_1\",\n",
      "    \"investment_level_2\",\n",
      "    \"investment_level_3\",\n",
      "    \"investments_measured_at_nav\",\n",
      "    \"investments_total_fair_value\"\n",
      "  ],\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This is to check if the schema is ok\n",
    "import json\n",
    "print(json.dumps(agent.data_schema, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449229a-af1c-4e6f-8219-6497a0a1bc94",
   "metadata": {},
   "source": [
    "The following two cell blocks extract all schools' info into one excel file per school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36077e96-e5ec-4352-afef-d76b8f78be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_school(school_name, school_dir):\n",
    "    combined   = {}\n",
    "    first_keys = None\n",
    "\n",
    "    for fname in sorted(os.listdir(school_dir)):\n",
    "        if not fname.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        path = os.path.join(school_dir, fname)\n",
    "        print(f\"Extracting data from {fname}\")\n",
    "        try:\n",
    "            run  = agent.extract(path)\n",
    "            data = run.data or {}\n",
    "            if first_keys is None:\n",
    "                first_keys = list(data.keys())\n",
    "                combined  = {k: None for k in first_keys}\n",
    "            for k, v in data.items():\n",
    "                if v not in (None, \"\", []):\n",
    "                    combined[k] = v\n",
    "        except Exception as err:\n",
    "            print(f\"Skipped {fname}: {err}\")\n",
    "\n",
    "    if first_keys:\n",
    "        df = pd.DataFrame.from_dict(combined, orient=\"index\", columns=[f\"{FISCAL_YEAR - 1}-{str(FISCAL_YEAR)[-2:]}\"])\n",
    "        df.index.name = \"Metric\"\n",
    "        outfile = os.path.join(OUTPUT_ROOT, f\"{school_name}.xlsx\")\n",
    "        df.to_excel(outfile)\n",
    "        print(f\"Saved output to {outfile}\")\n",
    "    else:\n",
    "        print(f\"No PDF data found for {school_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7256b8f-8158-48f2-8b89-5e1ae36760c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing school: BRADLEY_UNIVERSITY\n",
      "Extracting data from Annual_Financial_Information_and_Operating_Data__Rule_15c2-12__for_FY24_for_the_year_ended_05_31_2024__227_KB_.pdf\n",
      "Extracting data from Audited_Financial_Statements_or_ACFR__Rule_15c2-12__for_FY24_for_the_year_ended_05_31_2024__541_KB_.pdf\n",
      "Saved output to output_endowment_final/BRADLEY_UNIVERSITY.xlsx\n",
      "Processing school: CORNELL_UNIVERSITY\n",
      "Extracting data from 2024_Audited_Financial_Statements_for_the_year_ended_06_30_2024__788_KB_.pdf\n",
      "Extracting data from 2024_Operating_Data_for_the_year_ended_06_30_2024__109_KB_.pdf\n",
      "Extracting data from Incorporate_OS_by_Reference_as_of_04_25_2024__2.4_MB_.pdf\n",
      "Saved output to output_endowment_final/CORNELL_UNIVERSITY.xlsx\n",
      "Processing school: CULINARY_INSTITUTE_OF_AMERICA_THE\n",
      "Extracting data from 2024_Annual_Report_-_Corrected_for_the_year_ended_05_31_2024__130_KB_.pdf\n",
      "Extracting data from 2024_Annual_Report_for_the_year_ended_05_31_2024__129_KB_.pdf\n",
      "Extracting data from 2024_Audited_Financial_Statements_for_the_year_ended_05_31_2024__277_KB_.pdf\n",
      "Saved output to output_endowment_final/CULINARY_INSTITUTE_OF_AMERICA_THE.xlsx\n",
      "Processing school: GANNON_UNIVERSITY\n",
      "Extracting data from Audited_Financial_Statements_for_the_year_ended_06_30_2024__786_KB_.pdf\n",
      "Extracting data from Continued_Disclosures_Fall_2024_for_the_year_ended_06_30_2024_Document1__203_KB_.pdf\n",
      "Saved output to output_endowment_final/GANNON_UNIVERSITY.xlsx\n",
      "Processing school: LEWIS_UNIVERSITY\n",
      "Extracting data from Audited_Financial_Statements_for_the_year_ended_06_30_2024__430_KB_.pdf\n",
      "Extracting data from Continuing_Disclosure_for_the_year_ended_06_30_2024__298_KB_.pdf\n",
      "Saved output to output_endowment_final/LEWIS_UNIVERSITY.xlsx\n",
      "Processing school: MOLLOY_COLLEGE\n",
      "Extracting data from Financial_Operating_Filing_for_the_year_ended_06_30_2024_Document1__304_KB_.pdf\n",
      "Extracting data from Financial_Operating_Filing_for_the_year_ended_06_30_2024_Document2__142_KB_.pdf\n",
      "Saved output to output_endowment_final/MOLLOY_COLLEGE.xlsx\n",
      "Processing school: MOUNT_ST_MARY_S_UNIVERSITY_INC\n",
      "Extracting data from Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document1__29.1_MB_.pdf\n",
      "Extracting data from Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document2__5_MB_.pdf\n",
      "Saved output to output_endowment_final/MOUNT_ST_MARY_S_UNIVERSITY_INC.xlsx\n",
      "Processing school: NEW_YORK_UNIVERSITY\n",
      "Extracting data from 2024_Certificate_of_Compliance_-_Audit_for_the_year_ended_06_30_2024__330_KB_.pdf\n",
      "Extracting data from 2024_Certificate_of_Compliance_for_the_year_ended_06_30_2024__323_KB_.pdf\n",
      "Extracting data from 2024_Consolidated_Financial_Statements_New_York_University_for_the_year_ended_06_30_2024__466_KB_.pdf\n",
      "Extracting data from 2024_Operating_Data_for_the_year_ended_06_30_2024__244_KB_.pdf\n",
      "Saved output to output_endowment_final/NEW_YORK_UNIVERSITY.xlsx\n",
      "Processing school: PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE\n",
      "Extracting data from Harvard_University_Audited_Financial_Information_for_the_year_ended_06_30_2024__10.6_MB_.pdf\n",
      "Extracting data from Harvard_University_Financial_Report_for_the_year_ended_06_30_2024__10.6_MB_.pdf\n",
      "Extracting data from Harvard_University_Student_Applications_and_Enrollment_for_the_year_ended_06_30_2024__557_KB_.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating extraction jobs:   0%|          | 0/1 [04:15<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped Harvard_University_Student_Applications_and_Enrollment_for_the_year_ended_06_30_2024__557_KB_.pdf: Request timed out: \n",
      "Saved output to output_endowment_final/PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE.xlsx\n",
      "Processing school: STEVENSON_UNIVERSITY_INC\n",
      "Extracting data from 2024_Annual_Compliance_Certificate__EagleBank__for_the_year_ended_06_30_2024__3_MB_.pdf\n",
      "Extracting data from 2024_Annual_Compliance_Certificate_for_the_year_ended_06_30_2024__2.8_MB_.pdf\n",
      "Extracting data from 2024_Audited_Financial_Statements_for_the_year_ended_06_30_2024__348_KB_.pdf\n",
      "Extracting data from 2024_Operating_Data_for_the_year_ended_06_30_2024__196_KB_.pdf\n",
      "Saved output to output_endowment_final/STEVENSON_UNIVERSITY_INC.xlsx\n",
      "Processing school: STEVENS_INSTITUTE_OF_TECHNOLOGY\n",
      "Extracting data from Annual_Report_for_the_year_ended_06_30_2024__216_KB_.pdf\n",
      "Extracting data from Audit_Financial_Statement_for_the_year_ended_06_30_2024__626_KB_.pdf\n",
      "Saved output to output_endowment_final/STEVENS_INSTITUTE_OF_TECHNOLOGY.xlsx\n",
      "Processing school: ST_LOUIS_UNIVERSITY_US\n",
      "Extracting data from Amendment_to_Continuing_Disclosure_Undertaking_dated_01_05_2024__392_KB_.pdf\n",
      "Extracting data from Audited_Financials_and_Operating_Data_for_the_year_ended_06_30_2024_Document1__561_KB_.pdf\n",
      "Extracting data from Audited_Financials_and_Operating_Data_for_the_year_ended_06_30_2024_Document2__174_KB_.pdf\n",
      "Saved output to output_endowment_final/ST_LOUIS_UNIVERSITY_US.xlsx\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# Loop over schools\n",
    "for school in sorted(os.listdir(PDF_ROOT)):\n",
    "    school_dir = os.path.join(PDF_ROOT, school)\n",
    "    if not os.path.isdir(school_dir):\n",
    "        continue\n",
    "    print(f\"Processing school: {school}\")\n",
    "    process_school(school, school_dir)\n",
    "\n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b385406-d4f6-48e5-94b5-f999ee2e9f04",
   "metadata": {},
   "source": [
    "The following cell block extracts all the schools' info into one excel sheet but in different tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbed9f78-2b07-4696-8bd9-2ad2281d255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from BRADLEY_UNIVERSITY/Annual_Financial_Information_and_Operating_Data__Rule_15c2-12__for_FY24_for_the_year_ended_05_31_2024__227_KB_.pdf\n",
      "Extracting data from BRADLEY_UNIVERSITY/Audited_Financial_Statements_or_ACFR__Rule_15c2-12__for_FY24_for_the_year_ended_05_31_2024__541_KB_.pdf\n",
      "Extracting data from CORNELL_UNIVERSITY/2024_Audited_Financial_Statements_for_the_year_ended_06_30_2024__788_KB_.pdf\n",
      "Extracting data from CORNELL_UNIVERSITY/2024_Operating_Data_for_the_year_ended_06_30_2024__109_KB_.pdf\n",
      "Extracting data from CORNELL_UNIVERSITY/Incorporate_OS_by_Reference_as_of_04_25_2024__2.4_MB_.pdf\n",
      "Extracting data from CULINARY_INSTITUTE_OF_AMERICA_THE/2024_Annual_Report_-_Corrected_for_the_year_ended_05_31_2024__130_KB_.pdf\n",
      "Extracting data from CULINARY_INSTITUTE_OF_AMERICA_THE/2024_Annual_Report_for_the_year_ended_05_31_2024__129_KB_.pdf\n",
      "Extracting data from CULINARY_INSTITUTE_OF_AMERICA_THE/2024_Audited_Financial_Statements_for_the_year_ended_05_31_2024__277_KB_.pdf\n",
      "Extracting data from GANNON_UNIVERSITY/Audited_Financial_Statements_for_the_year_ended_06_30_2024__786_KB_.pdf\n",
      "Extracting data from GANNON_UNIVERSITY/Continued_Disclosures_Fall_2024_for_the_year_ended_06_30_2024_Document1__203_KB_.pdf\n",
      "Extracting data from LEWIS_UNIVERSITY/Audited_Financial_Statements_for_the_year_ended_06_30_2024__430_KB_.pdf\n",
      "Extracting data from LEWIS_UNIVERSITY/Continuing_Disclosure_for_the_year_ended_06_30_2024__298_KB_.pdf\n",
      "Extracting data from MOLLOY_COLLEGE/Financial_Operating_Filing_for_the_year_ended_06_30_2024_Document1__304_KB_.pdf\n",
      "Extracting data from MOLLOY_COLLEGE/Financial_Operating_Filing_for_the_year_ended_06_30_2024_Document2__142_KB_.pdf\n",
      "Extracting data from MOUNT_ST_MARY_S_UNIVERSITY_INC/Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document1__29.1_MB_.pdf\n",
      "Extracting data from MOUNT_ST_MARY_S_UNIVERSITY_INC/Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document2__5_MB_.pdf\n",
      "Extracting data from NEW_YORK_UNIVERSITY/2024_Certificate_of_Compliance_-_Audit_for_the_year_ended_06_30_2024__330_KB_.pdf\n",
      "Extracting data from NEW_YORK_UNIVERSITY/2024_Certificate_of_Compliance_for_the_year_ended_06_30_2024__323_KB_.pdf\n",
      "Extracting data from NEW_YORK_UNIVERSITY/2024_Consolidated_Financial_Statements_New_York_University_for_the_year_ended_06_30_2024__466_KB_.pdf\n",
      "Extracting data from NEW_YORK_UNIVERSITY/2024_Operating_Data_for_the_year_ended_06_30_2024__244_KB_.pdf\n",
      "Extracting data from PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE/Harvard_University_Audited_Financial_Information_for_the_year_ended_06_30_2024__10.6_MB_.pdf\n",
      "Extracting data from PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE/Harvard_University_Financial_Report_for_the_year_ended_06_30_2024__10.6_MB_.pdf\n",
      "Extracting data from PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE/Harvard_University_Student_Applications_and_Enrollment_for_the_year_ended_06_30_2024__557_KB_.pdf\n",
      "Extracting data from STEVENSON_UNIVERSITY_INC/2024_Annual_Compliance_Certificate__EagleBank__for_the_year_ended_06_30_2024__3_MB_.pdf\n",
      "Extracting data from STEVENSON_UNIVERSITY_INC/2024_Annual_Compliance_Certificate_for_the_year_ended_06_30_2024__2.8_MB_.pdf\n",
      "Extracting data from STEVENSON_UNIVERSITY_INC/2024_Audited_Financial_Statements_for_the_year_ended_06_30_2024__348_KB_.pdf\n",
      "Extracting data from STEVENSON_UNIVERSITY_INC/2024_Operating_Data_for_the_year_ended_06_30_2024__196_KB_.pdf\n",
      "Extracting data from STEVENS_INSTITUTE_OF_TECHNOLOGY/Annual_Report_for_the_year_ended_06_30_2024__216_KB_.pdf\n",
      "Extracting data from STEVENS_INSTITUTE_OF_TECHNOLOGY/Audit_Financial_Statement_for_the_year_ended_06_30_2024__626_KB_.pdf\n",
      "Extracting data from ST_LOUIS_UNIVERSITY_US/Amendment_to_Continuing_Disclosure_Undertaking_dated_01_05_2024__392_KB_.pdf\n",
      "Extracting data from ST_LOUIS_UNIVERSITY_US/Audited_Financials_and_Operating_Data_for_the_year_ended_06_30_2024_Document1__561_KB_.pdf\n",
      "Extracting data from ST_LOUIS_UNIVERSITY_US/Audited_Financials_and_Operating_Data_for_the_year_ended_06_30_2024_Document2__174_KB_.pdf\n",
      "All schools written to output_endowment_final/all_schools.xlsx\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = os.path.join(OUTPUT_ROOT, \"all_schools.xlsx\")\n",
    "\n",
    "writer = pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\")\n",
    "\n",
    "for school in sorted(os.listdir(PDF_ROOT)):\n",
    "    school_dir = os.path.join(PDF_ROOT, school)\n",
    "    if not os.path.isdir(school_dir):\n",
    "        continue\n",
    "\n",
    "    combined   = {}\n",
    "    first_keys = None\n",
    "    for fname in sorted(os.listdir(school_dir)):\n",
    "        if not fname.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        path = os.path.join(school_dir, fname)\n",
    "        print(f\"Extracting data from {school}/{fname}\")\n",
    "        try:\n",
    "            run  = agent.extract(path)\n",
    "            data = run.data or {}\n",
    "            if first_keys is None:\n",
    "                first_keys = list(data.keys())\n",
    "                combined  = {k: None for k in first_keys}\n",
    "            for k, v in data.items():\n",
    "                if v not in (None, \"\", []):\n",
    "                    combined[k] = v\n",
    "        except Exception as err:\n",
    "            print(f\"Skipped {fname}: {err}\")\n",
    "\n",
    "    if first_keys:\n",
    "        df = pd.DataFrame.from_dict(combined, orient=\"index\", columns=[f\"{FISCAL_YEAR - 1}-{str(FISCAL_YEAR)[-2:]}\"])\n",
    "        df.index.name = \"Metric\"\n",
    "        sheet_name = school[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name)\n",
    "    else:\n",
    "        print(f\"No data for {school}.\")\n",
    "\n",
    "writer.close()\n",
    "print(f\"All schools written to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6c073-4b51-4770-abc4-f5942a1f772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output_endowment_final/all_schools_combined.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Combine all the tabs into one sheet if wanted\n",
    "file_path   = \"output_endowment_final/all_schools.xlsx\"  #Change this if need be\n",
    "output_path = \"output_endowment_final/all_schools_combined.xlsx\" #Change this if need be\n",
    "\n",
    "raw = pd.read_excel(file_path, sheet_name=None, index_col=0)\n",
    "\n",
    "school_series = {\n",
    "    school: df.iloc[:, 0]                      # first (only) value column\n",
    "    for school, df in raw.items()\n",
    "}\n",
    "\n",
    "df_comb = pd.DataFrame(school_series).T\n",
    "df_comb.index.name = \"School\"                 \n",
    "df_comb.insert(0, \"Year\", f\"{FISCAL_YEAR - 1}–{FISCAL_YEAR}\")\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    df_comb.to_excel(writer, sheet_name=\"Combined\")\n",
    "\n",
    "print(\"Saved:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5ba9c-4240-49fe-8707-9c4fde4a09b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
